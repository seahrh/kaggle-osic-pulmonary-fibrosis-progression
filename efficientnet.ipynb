{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Dict, Any\n",
    "sns.set()\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./lib/kaggle-rig-0.2.0.tar.gz\n",
      "Requirement already satisfied: pandas~=1.1.1 in ./venv/lib/python3.7/site-packages (from kaggle-rig==0.2.0) (1.1.2)\n",
      "Requirement already satisfied: scikit-learn~=0.23.2 in ./venv/lib/python3.7/site-packages (from kaggle-rig==0.2.0) (0.23.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in ./venv/lib/python3.7/site-packages (from pandas~=1.1.1->kaggle-rig==0.2.0) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in ./venv/lib/python3.7/site-packages (from pandas~=1.1.1->kaggle-rig==0.2.0) (2020.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in ./venv/lib/python3.7/site-packages (from pandas~=1.1.1->kaggle-rig==0.2.0) (1.19.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./venv/lib/python3.7/site-packages (from scikit-learn~=0.23.2->kaggle-rig==0.2.0) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in ./venv/lib/python3.7/site-packages (from scikit-learn~=0.23.2->kaggle-rig==0.2.0) (0.16.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in ./venv/lib/python3.7/site-packages (from scikit-learn~=0.23.2->kaggle-rig==0.2.0) (1.4.1)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas~=1.1.1->kaggle-rig==0.2.0) (1.15.0)\n",
      "Building wheels for collected packages: kaggle-rig\n",
      "  Building wheel for kaggle-rig (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kaggle-rig: filename=kaggle_rig-0.2.0-py3-none-any.whl size=6539 sha256=8db5480a5c39561b716c49cc4608b9ffe0939a67c4f836a4614cd4953002c125\n",
      "  Stored in directory: /home/pankun/.cache/pip/wheels/03/99/72/07676e0abd65551d5261aee9360ad1c85fcaca1c409857a40a\n",
      "Successfully built kaggle-rig\n",
      "Installing collected packages: kaggle-rig\n",
      "  Attempting uninstall: kaggle-rig\n",
      "    Found existing installation: kaggle-rig 0.2.0\n",
      "    Uninstalling kaggle-rig-0.2.0:\n",
      "      Successfully uninstalled kaggle-rig-0.2.0\n",
      "Successfully installed kaggle-rig-0.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install lib/kaggle-rig-0.2.0.tar.gz\n",
    "import krig\n",
    "krig.seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Characters such as empty strings '' or numpy.inf are considered NA values\n",
    "pd.set_option('use_inf_as_na', True)\n",
    "pd.set_option('display.max_columns', 999)\n",
    "pd.set_option('display.max_rows', 999)\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'efficientnetb3'\n",
    "EPOCHS = 4\n",
    "LEARNING_RATE = 0.001\n",
    "DROPOUT = 0.01\n",
    "FOLDS = 10\n",
    "BATCH_SIZE = 32\n",
    "DATA = 'input/processed'\n",
    "TARGET = ['fvc_last_3', 'fvc_last_2', 'fvc_last_1']\n",
    "CONF = {\n",
    "    'efficientnetb0': {\n",
    "        'resolution': 224,\n",
    "        'output_size': 1280,\n",
    "    },\n",
    "    'efficientnetb1': {\n",
    "        'resolution': 240,\n",
    "        'output_size': 0,\n",
    "    },\n",
    "    'efficientnetb2': {\n",
    "        'resolution': 260,\n",
    "        'output_size': 1408,\n",
    "    },\n",
    "    'efficientnetb3': {\n",
    "        'resolution': 300,\n",
    "        'output_size': 1536,\n",
    "    },\n",
    "    'efficientnetb4': {\n",
    "        'resolution': 380,\n",
    "        'output_size': 0,\n",
    "    },\n",
    "    'efficientnetb5': {\n",
    "        'resolution': 456,\n",
    "        'output_size': 2048,\n",
    "    },\n",
    "    'efficientnetb6': {\n",
    "        'resolution': 528,\n",
    "        'output_size': 2304,\n",
    "    },\n",
    "    'efficientnetb7': {\n",
    "        'resolution': 600,\n",
    "        'output_size': 2560,\n",
    "    },\n",
    "}\n",
    "INPUT_SHAPE = (CONF[MODEL]['resolution'], CONF[MODEL]['resolution'], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32684 entries, 0 to 32683\n",
      "Data columns (total 14 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   pid          32684 non-null  object \n",
      " 1   age          32684 non-null  uint8  \n",
      " 2   sex          32684 non-null  object \n",
      " 3   smoking      32684 non-null  object \n",
      " 4   week_1       32684 non-null  int16  \n",
      " 5   fvc_1        32684 non-null  uint16 \n",
      " 6   percent_1    32684 non-null  float32\n",
      " 7   fvc_last_1   32684 non-null  uint16 \n",
      " 8   fvc_last_2   32684 non-null  uint16 \n",
      " 9   fvc_last_3   32684 non-null  uint16 \n",
      " 10  week_last_1  32684 non-null  int16  \n",
      " 11  week_last_2  32684 non-null  int16  \n",
      " 12  week_last_3  32684 non-null  int16  \n",
      " 13  img          32684 non-null  object \n",
      "dtypes: float32(1), int16(4), object(4), uint16(4), uint8(1)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_parquet(f'{DATA}/train.parquet')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoking</th>\n",
       "      <th>week_1</th>\n",
       "      <th>fvc_1</th>\n",
       "      <th>percent_1</th>\n",
       "      <th>fvc_last_1</th>\n",
       "      <th>fvc_last_2</th>\n",
       "      <th>fvc_last_3</th>\n",
       "      <th>week_last_1</th>\n",
       "      <th>week_last_2</th>\n",
       "      <th>week_last_3</th>\n",
       "      <th>img</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "      <td>-4</td>\n",
       "      <td>2315</td>\n",
       "      <td>58.253647</td>\n",
       "      <td>2057</td>\n",
       "      <td>2064</td>\n",
       "      <td>2000</td>\n",
       "      <td>57</td>\n",
       "      <td>41</td>\n",
       "      <td>29</td>\n",
       "      <td>ID00007637202177411956430/0.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "      <td>-4</td>\n",
       "      <td>2315</td>\n",
       "      <td>58.253647</td>\n",
       "      <td>2057</td>\n",
       "      <td>2064</td>\n",
       "      <td>2000</td>\n",
       "      <td>57</td>\n",
       "      <td>41</td>\n",
       "      <td>29</td>\n",
       "      <td>ID00007637202177411956430/1.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "      <td>-4</td>\n",
       "      <td>2315</td>\n",
       "      <td>58.253647</td>\n",
       "      <td>2057</td>\n",
       "      <td>2064</td>\n",
       "      <td>2000</td>\n",
       "      <td>57</td>\n",
       "      <td>41</td>\n",
       "      <td>29</td>\n",
       "      <td>ID00007637202177411956430/10.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "      <td>-4</td>\n",
       "      <td>2315</td>\n",
       "      <td>58.253647</td>\n",
       "      <td>2057</td>\n",
       "      <td>2064</td>\n",
       "      <td>2000</td>\n",
       "      <td>57</td>\n",
       "      <td>41</td>\n",
       "      <td>29</td>\n",
       "      <td>ID00007637202177411956430/11.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "      <td>-4</td>\n",
       "      <td>2315</td>\n",
       "      <td>58.253647</td>\n",
       "      <td>2057</td>\n",
       "      <td>2064</td>\n",
       "      <td>2000</td>\n",
       "      <td>57</td>\n",
       "      <td>41</td>\n",
       "      <td>29</td>\n",
       "      <td>ID00007637202177411956430/12.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         pid  age   sex    smoking  week_1  fvc_1  percent_1  \\\n",
       "0  ID00007637202177411956430   79  Male  Ex-smoker      -4   2315  58.253647   \n",
       "1  ID00007637202177411956430   79  Male  Ex-smoker      -4   2315  58.253647   \n",
       "2  ID00007637202177411956430   79  Male  Ex-smoker      -4   2315  58.253647   \n",
       "3  ID00007637202177411956430   79  Male  Ex-smoker      -4   2315  58.253647   \n",
       "4  ID00007637202177411956430   79  Male  Ex-smoker      -4   2315  58.253647   \n",
       "\n",
       "   fvc_last_1  fvc_last_2  fvc_last_3  week_last_1  week_last_2  week_last_3  \\\n",
       "0        2057        2064        2000           57           41           29   \n",
       "1        2057        2064        2000           57           41           29   \n",
       "2        2057        2064        2000           57           41           29   \n",
       "3        2057        2064        2000           57           41           29   \n",
       "4        2057        2064        2000           57           41           29   \n",
       "\n",
       "                                img  \n",
       "0   ID00007637202177411956430/0.png  \n",
       "1   ID00007637202177411956430/1.png  \n",
       "2  ID00007637202177411956430/10.png  \n",
       "3  ID00007637202177411956430/11.png  \n",
       "4  ID00007637202177411956430/12.png  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(data)=32684, len(train)=29410, len(val)=3274\n"
     ]
    }
   ],
   "source": [
    "spl = sklearn.model_selection.GroupKFold(n_splits=FOLDS)\n",
    "x = data['img']\n",
    "y = data[TARGET]\n",
    "groups = data['pid']\n",
    "train = val = None\n",
    "i = 0\n",
    "for train_indices, test_indices in spl.split(x, y, groups):\n",
    "    if i != 0:\n",
    "        break\n",
    "    train = data.iloc[train_indices]\n",
    "    val = data.iloc[test_indices]\n",
    "    i += 1\n",
    "\n",
    "\n",
    "print(f'len(data)={len(data)}, len(train)={len(train)}, len(val)={len(val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "efficientnetb3 (Functional)  (None, 1536)              10783535  \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 1536)              6144      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1536)              2360832   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 3)                 4611      \n",
      "=================================================================\n",
      "Total params: 13,155,122\n",
      "Trainable params: 2,368,515\n",
      "Non-trainable params: 10,786,607\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Transfer learning from underlying pretrained model (freeze weights!)\n",
    "# do not include output layer from pretrained model\n",
    "pretrained = keras.applications.EfficientNetB3(\n",
    "    include_top=False, input_shape=INPUT_SHAPE, pooling='max', weights='imagenet'\n",
    ")\n",
    "pretrained.trainable = False\n",
    "kernel_initializer = keras.initializers.he_normal()\n",
    "kernel_regularizer = keras.regularizers.l2(0.01) \n",
    "model = keras.models.Sequential()\n",
    "model.add(pretrained)\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Dense(\n",
    "    CONF[MODEL]['output_size'],\n",
    "    activation=\"relu\",\n",
    "    kernel_initializer=kernel_initializer,\n",
    "    kernel_regularizer=kernel_regularizer\n",
    "))\n",
    "model.add(keras.layers.Dropout(DROPOUT))\n",
    "model.add(keras.layers.Dense(len(TARGET), name='output'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=2, verbose=1, factor=0.5),\n",
    "    keras.callbacks.EarlyStopping(monitor='val_loss', patience=4),\n",
    "    keras.callbacks.ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)\n",
    "]\n",
    "optimizer = keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "loss = keras.losses.MeanSquaredLogarithmicError()\n",
    "rmse = keras.metrics.RootMeanSquaredError()\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=[rmse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29410 validated image filenames.\n",
      "Found 3274 validated image filenames.\n",
      "Found 32684 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "target_size = (INPUT_SHAPE[0], INPUT_SHAPE[1])\n",
    "color_mode='rgb'\n",
    "class_mode='multi_output'\n",
    "idg = keras.preprocessing.image.ImageDataGenerator()\n",
    "\n",
    "train_gen = idg.flow_from_dataframe(\n",
    "    dataframe = train,\n",
    "    x_col='img',\n",
    "    y_col=TARGET,\n",
    "    directory=DATA,\n",
    "    target_size=target_size,\n",
    "    color_mode=color_mode,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    class_mode=class_mode\n",
    ")\n",
    "\n",
    "val_gen = idg.flow_from_dataframe(\n",
    "    dataframe = val,\n",
    "    x_col='img',\n",
    "    y_col=TARGET,\n",
    "    directory=DATA,\n",
    "    target_size=target_size,\n",
    "    color_mode=color_mode,\n",
    "    shuffle=False,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=class_mode\n",
    ")\n",
    "\n",
    "test_gen = idg.flow_from_dataframe(\n",
    "    dataframe = data,\n",
    "    x_col='img',\n",
    "    y_col=TARGET,\n",
    "    directory=DATA,\n",
    "    target_size=target_size,\n",
    "    color_mode=color_mode,\n",
    "    shuffle=False,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=class_mode\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "920/920 [==============================] - 6403s 7s/step - loss: 9.4782 - root_mean_squared_error: 2419.6580 - val_loss: 1.4317 - val_root_mean_squared_error: 1433.5941\n",
      "Epoch 2/4\n",
      "920/920 [==============================] - 6205s 7s/step - loss: 1.1738 - root_mean_squared_error: 1638.7969 - val_loss: 0.6367 - val_root_mean_squared_error: 1026.1725\n",
      "Epoch 3/4\n",
      "920/920 [==============================] - 6175s 7s/step - loss: 0.5970 - root_mean_squared_error: 1282.1606 - val_loss: 0.4207 - val_root_mean_squared_error: 857.5153\n",
      "Epoch 4/4\n",
      "460/920 [==============>...............] - ETA: 46:24 - loss: 0.4113 - root_mean_squared_error: 1123.4467"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_gen,\n",
    "          epochs=EPOCHS, \n",
    "          validation_data=val_gen,#class_weight=class_weights_dict,\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    h = pd.DataFrame(history.history)\n",
    "    h['epoch'] = history.epoch\n",
    "    h['epoch'] = h['epoch'] + 1\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.plot(h['epoch'], h['loss'],label='Train')\n",
    "    plt.plot(h['epoch'], h['val_loss'],label='Val')\n",
    "    plt.legend()\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('RMSE')\n",
    "    plt.plot(h['epoch'], h['root_mean_squared_error'], label='Train')\n",
    "    plt.plot(h['epoch'], h['val_root_mean_squared_error'], label='Val')\n",
    "    plt.legend()\n",
    "    plt.figure()\n",
    "    plt.xlabel('Learning Rate')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.plot(h['lr']*-1, h['loss'], label='Train')\n",
    "    plt.plot(h['lr']*-1, h['val_loss'], label='Val')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('best_model.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(test_gen, use_multiprocessing=False, workers=4, verbose=1)\n",
    "print(f'preds.shape={preds.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = preds.T\n",
    "data['fvc_last_3_cv'] = preds[0]\n",
    "data['fvc_last_2_cv'] = preds[1]\n",
    "data['fvc_last_1_cv'] = preds[2]\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['img'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_dist(row, fvc_last_1_cv, fvc_last_2_cv, fvc_last_3_cv) -> None:\n",
    "    quantiles = [0, 0.5, 0.75, 0.9, 0.95, 0.99, 1]\n",
    "    s = pd.Series(fvc_last_1_cv)\n",
    "    qs = s.quantile(quantiles).to_numpy()\n",
    "    row['fvc_last_1_min'] = qs[0]\n",
    "    row['fvc_last_1_p50'] = qs[1]\n",
    "    row['fvc_last_1_p75'] = qs[2]\n",
    "    row['fvc_last_1_p90'] = qs[3]\n",
    "    row['fvc_last_1_p95'] = qs[4]\n",
    "    row['fvc_last_1_p99'] = qs[5]\n",
    "    row['fvc_last_1_max'] = qs[6]\n",
    "    s = pd.Series(fvc_last_2_cv)\n",
    "    qs = s.quantile(quantiles).to_numpy()\n",
    "    row['fvc_last_2_min'] = qs[0]\n",
    "    row['fvc_last_2_p50'] = qs[1]\n",
    "    row['fvc_last_2_p75'] = qs[2]\n",
    "    row['fvc_last_2_p90'] = qs[3]\n",
    "    row['fvc_last_2_p95'] = qs[4]\n",
    "    row['fvc_last_2_p99'] = qs[5]\n",
    "    row['fvc_last_2_max'] = qs[6]\n",
    "    s = pd.Series(fvc_last_3_cv)\n",
    "    qs = s.quantile(quantiles).to_numpy()\n",
    "    row['fvc_last_3_min'] = qs[0]\n",
    "    row['fvc_last_3_p50'] = qs[1]\n",
    "    row['fvc_last_3_p75'] = qs[2]\n",
    "    row['fvc_last_3_p90'] = qs[3]\n",
    "    row['fvc_last_3_p95'] = qs[4]\n",
    "    row['fvc_last_3_p99'] = qs[5]\n",
    "    row['fvc_last_3_max'] = qs[6]\n",
    "\n",
    "\n",
    "\n",
    "rows = []\n",
    "row: Dict[str, Any] = {}\n",
    "prev = None\n",
    "fvc_last_1_cv = []\n",
    "fvc_last_2_cv = []\n",
    "fvc_last_3_cv = []\n",
    "for t in data.itertuples():\n",
    "    # new patient\n",
    "    if prev is not None and prev != t.pid:\n",
    "        set_dist(row, fvc_last_1_cv, fvc_last_2_cv, fvc_last_3_cv)\n",
    "        rows.append(row)\n",
    "    if prev is None or prev != t.pid:\n",
    "        row = {}\n",
    "        fvc_last_1_cv = []\n",
    "        fvc_last_2_cv = []\n",
    "        fvc_last_3_cv = []\n",
    "        row['pid'] = t.pid\n",
    "        row['age'] = t.age\n",
    "        row['sex'] = t.sex\n",
    "        row['smoking'] = t.smoking\n",
    "        row['week_1'] = t.week_1\n",
    "        row['fvc_1'] = t.fvc_1\n",
    "        row['percent_1'] = t.percent_1\n",
    "        row['fvc_last_1'] = t.fvc_last_1\n",
    "        row['fvc_last_2'] = t.fvc_last_2\n",
    "        row['fvc_last_3'] = t.fvc_last_3\n",
    "        row['week_last_1'] = t.week_last_1\n",
    "        row['week_last_2'] = t.week_last_2\n",
    "        row['week_last_3'] = t.week_last_3\n",
    "    prev = t.pid\n",
    "    fvc_last_1_cv.append(t.fvc_last_1_cv)\n",
    "    fvc_last_2_cv.append(t.fvc_last_2_cv)\n",
    "    fvc_last_3_cv.append(t.fvc_last_3_cv)\n",
    "    \n",
    "# add the last patient!\n",
    "if len(row) != 0:\n",
    "    set_dist(row, fvc_last_1_cv, fvc_last_2_cv, fvc_last_3_cv)\n",
    "    rows.append(row)\n",
    "\n",
    "\n",
    "schema = {\n",
    "    'pid': str,\n",
    "    'age': np.uint8,\n",
    "    'sex': str,\n",
    "    'smoking': str,\n",
    "    'week_1': np.int16,\n",
    "    'fvc_1': np.uint16,\n",
    "    'percent_1': np.float32,\n",
    "    'fvc_last_1': np.uint16,\n",
    "    'fvc_last_2': np.uint16,\n",
    "    'fvc_last_3': np.uint16,\n",
    "    'week_last_1': np.int16,\n",
    "    'week_last_2': np.int16,\n",
    "    'week_last_3': np.int16,\n",
    "    'fvc_last_1_min': np.float32,\n",
    "    'fvc_last_1_p50': np.float32,\n",
    "    'fvc_last_1_p75': np.float32,\n",
    "    'fvc_last_1_p90': np.float32,\n",
    "    'fvc_last_1_p95': np.float32,\n",
    "    'fvc_last_1_p99': np.float32,\n",
    "    'fvc_last_1_max': np.float32,\n",
    "    'fvc_last_2_min': np.float32,\n",
    "    'fvc_last_2_p50': np.float32,\n",
    "    'fvc_last_2_p75': np.float32,\n",
    "    'fvc_last_2_p90': np.float32,\n",
    "    'fvc_last_2_p95': np.float32,\n",
    "    'fvc_last_2_p99': np.float32,\n",
    "    'fvc_last_2_max': np.float32,\n",
    "    'fvc_last_3_min': np.float32,\n",
    "    'fvc_last_3_p50': np.float32,\n",
    "    'fvc_last_3_p75': np.float32,\n",
    "    'fvc_last_3_p90': np.float32,\n",
    "    'fvc_last_3_p95': np.float32,\n",
    "    'fvc_last_3_p99': np.float32,\n",
    "    'fvc_last_3_max': np.float32,\n",
    "}\n",
    "train = pd.DataFrame.from_records(rows)\n",
    "assert len(train) == 174\n",
    "train = train.astype(schema)\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_parquet('output/cvtrain.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
